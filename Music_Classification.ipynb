{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch range: 288.100341796875 to 2310.0126953125\n",
      "Tempo range: 67.99958881578948 to 287.109375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backward       1.00      0.99      1.00       146\n",
      "     forward       0.99      1.00      1.00       158\n",
      "        left       1.00      1.00      1.00       141\n",
      "       right       1.00      1.00      1.00       155\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the path to the audio files\n",
    "audio_path_pop = '/home/minhah/vc/genres_original/pop/'\n",
    "\n",
    "# Initialize an empty list to hold features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Define a function to extract features from an audio file\n",
    "def extract_features(y, sr):\n",
    "    # Extract pitch (using librosa's pitch detection)\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch = pitches[magnitudes > np.median(magnitudes)].mean() if magnitudes.any() else 0\n",
    "\n",
    "    # Extract tempo (using librosa's tempo detection)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    return pitch, tempo\n",
    "\n",
    "# Initialize lists to hold pitch and tempo values\n",
    "pitches = []\n",
    "tempos = []\n",
    "\n",
    "# Loop through each file in the pop directory and extract features\n",
    "for file_name in os.listdir(audio_path_pop):\n",
    "    if file_name.endswith('.wav'):\n",
    "        full_file_name = os.path.join(audio_path_pop, file_name)\n",
    "        \n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(full_file_name, sr=None)\n",
    "        \n",
    "        # Divide audio into 1-second segments\n",
    "        for start in range(0, len(y), sr):\n",
    "            end = start + sr\n",
    "            segment = y[start:end]\n",
    "            if len(segment) < sr:\n",
    "                break\n",
    "\n",
    "            # Extract features from the segment\n",
    "            pitch, tempo = extract_features(segment, sr)\n",
    "            # Append the pitch and tempo to the lists\n",
    "            pitches.append(pitch)\n",
    "            tempos.append(tempo)\n",
    "\n",
    "# Convert lists to numpy arrays for easy manipulation\n",
    "pitches = np.array(pitches)\n",
    "tempos = np.array(tempos)\n",
    "\n",
    "# Calculate the range for pitch and tempo\n",
    "pitch_min = np.min(pitches)\n",
    "pitch_max = np.max(pitches)\n",
    "tempo_min = np.min(tempos)\n",
    "tempo_max = np.max(tempos)\n",
    "\n",
    "print(f'Pitch range: {pitch_min} to {pitch_max}')\n",
    "print(f'Tempo range: {tempo_min} to {tempo_max}')\n",
    "\n",
    "# Define thresholds\n",
    "pitch_threshold = 1268  # Example threshold for pitch\n",
    "tempo_threshold = 136  # Example threshold for tempo\n",
    "\n",
    "# Loop through each file in the pop directory and extract features\n",
    "for file_name in os.listdir(audio_path_pop):\n",
    "    if file_name.endswith('.wav'):\n",
    "        full_file_name = os.path.join(audio_path_pop, file_name)\n",
    "        \n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(full_file_name, sr=None)\n",
    "        \n",
    "        # Divide audio into 1-second segments\n",
    "        for start in range(0, len(y), sr):\n",
    "            end = start + sr\n",
    "            segment = y[start:end]\n",
    "            if len(segment) < sr:\n",
    "                break\n",
    "\n",
    "            # Extract features from the segment\n",
    "            pitch, tempo = extract_features(segment, sr)\n",
    "            \n",
    "            if pitch is not None and tempo[0] is not None:\n",
    "                # Define the label based on pitch and tempo\n",
    "                if pitch < pitch_threshold and tempo[0] < tempo_threshold:\n",
    "                    label = 'backward'\n",
    "                elif pitch < pitch_threshold and tempo[0] >= tempo_threshold:\n",
    "                    label = 'left'\n",
    "                elif pitch >= pitch_threshold and tempo[0] < tempo_threshold:\n",
    "                    label = 'forward'\n",
    "                else:\n",
    "                    label = 'right'\n",
    "                \n",
    "                # Append the features and label to the lists\n",
    "                features.append([pitch, tempo[0]])\n",
    "                labels.append(label)\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Support Vector Classifier (SVC)\n",
    "classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained classifier and scaler\n",
    "joblib.dump(classifier, 'classifier.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directions:\n",
      "['forward', 'right', 'right', 'forward', 'forward', 'forward', 'right', 'forward', 'forward', 'forward', 'forward', 'forward', 'forward', 'right', 'forward', 'forward', 'backward', 'forward', 'forward', 'backward', 'forward', 'forward', 'forward', 'forward', 'right', 'right', 'forward', 'forward', 'forward', 'forward']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "\n",
    "# Define a function to extract features from an audio file\n",
    "def extract_features(y, sr):\n",
    "    # Extract pitch (using librosa's pitch detection)\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch = pitches[magnitudes > np.median(magnitudes)].mean() if magnitudes.any() else 0\n",
    "\n",
    "    # Extract tempo (using librosa's tempo detection)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    return pitch, tempo\n",
    "\n",
    "# Function to process a single audio file and return directions per second\n",
    "def process_audio_file(file_path):\n",
    "    # Load the trained classifier and scaler\n",
    "    classifier = joblib.load('classifier.joblib')\n",
    "    scaler = joblib.load('scaler.joblib')\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    directions = []\n",
    "    \n",
    "    # Divide audio into 1-second segments\n",
    "    for start in range(0, len(y), sr):\n",
    "        end = start + sr\n",
    "        segment = y[start:end]\n",
    "        if len(segment) < sr:\n",
    "            break\n",
    "\n",
    "        # Extract features from the segment\n",
    "        pitch, tempo = extract_features(segment, sr)\n",
    "        \n",
    "        if pitch is not None and tempo is not None:\n",
    "            # Predict the direction using the trained classifier\n",
    "            feature = np.array([[pitch, tempo[0]]])\n",
    "            feature = scaler.transform(feature)  # Scale the features\n",
    "            direction = classifier.predict(feature)[0]\n",
    "            directions.append(direction)\n",
    "    \n",
    "    return directions\n",
    "\n",
    "# Define the path to the rock audio files\n",
    "audio_path = '/home/minhah/vc/genres_original/rock/rock.00086.wav'\n",
    "directions = process_audio_file(audio_path)\n",
    "\n",
    "# Print the directions\n",
    "print(f'Directions:\\n{directions}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directions:\n",
      "['left', 'left', 'left', 'left', 'backward', 'left', 'left', 'left', 'left', 'right', 'left', 'backward', 'right', 'right', 'left', 'left', 'left', 'left', 'left', 'left', 'left', 'backward', 'left', 'backward', 'left', 'forward', 'left', 'left', 'backward', 'left']\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the rock audio files\n",
    "audio_path = '/home/minhah/vc/genres_original/country/country.00002.wav'\n",
    "directions = process_audio_file(audio_path)\n",
    "\n",
    "# Print the directions\n",
    "print(f'Directions:\\n{directions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ER)",
   "language": "python",
   "name": "er"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
